{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78f48544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5587 files belonging to 10 classes.\n",
      "Found 1559 files belonging to 10 classes.\n",
      "Found 52 files belonging to 10 classes.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 32, 32, 3)        0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 32, 32, 3)        0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 8, 8, 256)         229760    \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 232,330\n",
      "Trainable params: 229,386\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjali\\anaconda3\\envs\\dvc\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 34.016395568847656, acc 0.09236690402030945\n",
      "Epoch 1/10\n",
      "699/699 - 32s - loss: 1.6668 - accuracy: 0.4285 - val_loss: 1.2214 - val_accuracy: 0.5581 - 32s/epoch - 46ms/step\n",
      "Epoch 2/10\n",
      "699/699 - 23s - loss: 1.0139 - accuracy: 0.6603 - val_loss: 0.8212 - val_accuracy: 0.7460 - 23s/epoch - 33ms/step\n",
      "Epoch 3/10\n",
      "699/699 - 23s - loss: 0.7491 - accuracy: 0.7582 - val_loss: 0.7591 - val_accuracy: 0.7396 - 23s/epoch - 33ms/step\n",
      "Epoch 4/10\n",
      "699/699 - 24s - loss: 0.5870 - accuracy: 0.8099 - val_loss: 0.5536 - val_accuracy: 0.8185 - 24s/epoch - 34ms/step\n",
      "Epoch 5/10\n",
      "699/699 - 23s - loss: 0.4707 - accuracy: 0.8527 - val_loss: 0.6253 - val_accuracy: 0.7858 - 23s/epoch - 33ms/step\n",
      "Epoch 6/10\n",
      "699/699 - 23s - loss: 0.4020 - accuracy: 0.8701 - val_loss: 0.4708 - val_accuracy: 0.8563 - 23s/epoch - 33ms/step\n",
      "Epoch 7/10\n",
      "699/699 - 23s - loss: 0.3270 - accuracy: 0.9023 - val_loss: 0.4587 - val_accuracy: 0.8473 - 23s/epoch - 33ms/step\n",
      "Epoch 8/10\n",
      "699/699 - 23s - loss: 0.3001 - accuracy: 0.9071 - val_loss: 0.4111 - val_accuracy: 0.8724 - 23s/epoch - 33ms/step\n",
      "Epoch 9/10\n",
      "699/699 - 22s - loss: 0.2416 - accuracy: 0.9316 - val_loss: 0.5293 - val_accuracy: 0.8262 - 22s/epoch - 32ms/step\n",
      "Epoch 10/10\n",
      "699/699 - 22s - loss: 0.1961 - accuracy: 0.9449 - val_loss: 0.4725 - val_accuracy: 0.8589 - 22s/epoch - 32ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "\n",
    "directory = \"data_11-whitespace-aug\"\n",
    "user_data = directory #  + \"/train\"\n",
    "valid_data = directory #  + \"/val\"\n",
    "test_data = directory   + \"/label_book\" # this can be the label book, or any other test set you create\n",
    "# test_data = directory + \"/test\" # this can be the label book, or any other test set you create\n",
    "\n",
    "### DO NOT MODIFY BELOW THIS LINE, THIS IS THE FIXED MODEL ###\n",
    "batch_size = 8\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        user_data + '/train',\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n",
    "        shuffle=True,\n",
    "        seed=123,\n",
    "        batch_size=batch_size,\n",
    "        image_size=(32, 32),\n",
    "    )\n",
    "\n",
    "    valid = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        user_data + '/val',\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n",
    "        shuffle=True,\n",
    "        seed=123,\n",
    "        batch_size=batch_size,\n",
    "        image_size=(32, 32),\n",
    "    )\n",
    "\n",
    "    total_length = ((train.cardinality() + valid.cardinality()) * batch_size).numpy()\n",
    "    if total_length > 10_000:\n",
    "        print(f\"Dataset size larger than 10,000. Got {total_length} examples\")\n",
    "        sys.exit()\n",
    "\n",
    "    test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        test_data,\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n",
    "        shuffle=False,\n",
    "        seed=123,\n",
    "        batch_size=batch_size,\n",
    "        image_size=(32, 32),\n",
    "    )\n",
    "\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        input_shape=(32, 32, 3),\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "    )\n",
    "    base_model = tf.keras.Model(\n",
    "        base_model.inputs, outputs=[base_model.get_layer(\"conv2_block3_out\").output]\n",
    "    )\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "    x = base_model(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(10)(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    model.summary()\n",
    "    loss_0, acc_0 = model.evaluate(valid, verbose=0)\n",
    "    print(f\"loss {loss_0}, acc {acc_0}\")\n",
    "\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model\",\n",
    "        monitor=\"val_accuracy\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train,\n",
    "        validation_data=valid,\n",
    "        epochs=10,\n",
    "        callbacks=[checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c434c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss 0.4111422896385193, final acc 0.8723540902137756\n",
      "test loss 1.2760112285614014, test acc 0.7307692170143127\n"
     ]
    }
   ],
   "source": [
    " model.load_weights(\"best_model\")\n",
    "\n",
    "loss, acc = model.evaluate(valid, verbose=0)\n",
    "print(f\"final loss {loss}, final acc {acc}\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test, verbose=0)\n",
    "print(f\"test loss {test_loss}, test acc {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78e082a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonString = json.dumps({\"train_loss\":loss , \"train_acc\": acc}, indent=4)\n",
    "jsonFile = open(\"test_result.json\", \"w\")\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe271ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonString = json.dumps({\"train_loss\":test_loss , \"test_acc\": test_acc}, indent=4)\n",
    "jsonFile = open(\"train_result.json\", \"w\")\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49de29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
